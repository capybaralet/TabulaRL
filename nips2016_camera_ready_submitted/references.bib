@inproceedings{Subramanian2016,
 author = {Subramanian, Kaushik and Isbell,Jr., Charles L. and Thomaz, Andrea L.},
 title = {Exploration from Demonstration for Interactive Reinforcement Learning},
 booktitle = {International Conference on Autonomous Agents \&\#38; Multiagent Systems},
 year = {2016},
} 


@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{sutton1998reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  volume={1},
  number={1},
  year={1998},
  publisher={MIT press Cambridge}
}

@article{osband2016posterior,
  title={Why is Posterior Sampling Better than Optimism for Reinforcement Learning},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={arXiv preprint arXiv:1607.00215},
  year={2016}
}


@inproceedings{ng2000algorithms,
  title={Algorithms for inverse reinforcement learning.},
  author={Ng, Andrew Y and Russell, Stuart J},
  booktitle={International Conference on Machine Learning},
  year={2000}
}



@article{evans2015learning,
  title={Learning the preferences of ignorant, inconsistent agents},
  author={Evans, Owain and Stuhlm{\"u}ller, Andreas and Goodman, Noah D},
  journal={arXiv preprint arXiv:1512.05832},
  year={2015}
}

@inproceedings{wirth2013preference,
  title={Preference-based reinforcement learning: A preliminary survey},
  author={Wirth, Christian and F{\"u}rnkranz, Johannes},
  booktitle={The ECML/PKDD-13 Workshop on Reinforcement Learning from Generalized Feedback: Beyond Numeric Rewards},
  year={2013}
}

@book{bostrom2014superintelligence,
  title={Superintelligence: Paths, dangers, strategies},
  author={Bostrom, Nick},
  year={2014},
  publisher={OUP Oxford}
}

@article{chapelle2009semi,
  title={Semi-Supervised Learning (Chapelle, O. et al., Eds.; 2006)[Book reviews]},
  author={Chapelle, Olivier and Scholkopf, Bernhard and Zien, Alexander},
  journal={IEEE Transactions on Neural Networks},
  volume={20},
  number={3},
  pages={542--542},
  year={2009},
  publisher={IEEE}
}

@inproceedings{weng2013interactive,
  title={Interactive {Q}-learning with ordinal rewards and unreliable tutor},
  author={Weng, Paul and Busa-Fekete, Robert and H{\"u}llermeier, Eyke},
  booktitle={The ECML/PKDD-13 Workshop on Reinforcement Learning from Generalized Feedback: Beyond Numeric Rewards},
  year={2013}
}

@inproceedings{knox2009interactively,
  title={Interactively shaping agents via human reinforcement: The {TAMER} framework},
  author={Knox, W Bradley and Stone, Peter},
  booktitle={International Conference on Knowledge Capture},
  year={2009},
  organization={ACM}
}

@article{lopes2014active,
  title={Active learning for autonomous intelligent agents: Exploration, curiosity, and interaction},
  author={Lopes, Manuel and Montesano, Luis},
  journal={arXiv preprint arXiv:1403.1497},
  year={2014}
}

@inproceedings{regan2011robust,
  title={Robust online optimization of reward-uncertain {MDP}s},
 author = {Regan, Kevin and Boutilier, Craig},
 booktitle = {International Joint Conference on Artificial Intelligence},
 year = {2011},
} 


@article{MDPNv1,
  author    = {Philip S. Thomas, Billy Okal},
  title     = {A Notation for {M}arkov decision processes},
  journal   = {CoRR},
  volume    = {abs/1512.09075},
  year      = {2015},
}

@article{ConcreteProblems,
  author    = {Dario Amodei and
               Chris Olah and
               Jacob Steinhardt and
               Paul Christiano and
               John Schulman and
               Dan Man{\'{e}}},
  title     = {Concrete Problems in {AI} Safety},
  journal   = {CoRR},
  volume    = {abs/1606.06565},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.06565},
}

@inproceedings{DanielVMKP2014,
  title = {Active Reward Learning},
  author = {Daniel, C. and Viering, M. and Metz, J. and Kroemer, O. and Peters, J.},
  booktitle = {Robotics: Science \& Systems},
  editors = {Fox, D., Kavraki, LE., and Kurniawati, H.},
  year = {2014}
}




@misc{EVSI,
   title = "Applied statistical decision theory",
   author = "Raiffa, Howard and Schlaifer, Robert",
   series = "Studies in managerial economics",
   publisher = "Division of Research, Graduate School of Business Adminitration, Harvard University",
   pages = "87-92",
   address = "Boston",
   url = "http://opac.inria.fr/record=b1082847",
   year = 1961
}

@article{TS1933,
  author =       "William R. Thompson",
  title =        "On the Likelihood that One Unknown Probability Exceeds
                 Another in View of the Evidence of Two Samples",
  journal =      j-BIOMETRIKA,
  volume =       "25",
  number =       "3/4",
  pages =        "285--294",
  year =         "1933",
}

@inproceedings{Piccolboni01,
  title={Discrete Prediction Games with Arbitrary Feedback and Loss},
  author={Piccolboni, Antonio and Schindelhauer, Christian},
  booktitle={Computational Learning Theory},
  year={2001}
}

@article{Antos13,
  title={Toward a Classification of Finite Partial-Monitoring Games},
  author={Antos, András and Bartók, Gábor and Pál, Dávid and Szepesvári, Csaba},
  journal={Theoretical Computer Science},
  volume={473},
  pages={77--99},
  year={2013}
}

@inproceedings{Komiyama15,
  title={Regret Lower Bound and Optimal Algorithm in Finite Stochastic Partial Monitoring},
  author={Komiyama, Junpei and Honda, Junya and Nakagawa, Hiroshi},
  booktitle={Neural Information Processing Systems},
  year={2015}
}

@inproceedings{Hay12,
  title={Selecting Computations: Theory and Applications},
  author={Hay, Nicholas and Russell, Stuart and Tolpin, David and Shimony, Solomon Eyal},
  booktitle={Uncertainty in Artificial Intelligence},
  year={2012}
}

@article{Bubeck12,
  title={Regret Analysis of Stochastic and Nonstochastic Multi-Armed Bandit Problems},
  author={Bubeck, Sébastien and Cesa-Bianchi, Nicolo},
  journal={Machine Learning},
  volume={5},
  number={1},
  pages={1--122},
  year={2012}
}

@inproceedings{Madani04,
  title={The Budgeted Multi-Armed Bandit Problem},
  author={Madani, Omid and Lizotte, Daniel J and Greiner, Russell},
  booktitle={Computational Learning Theory},
  year={2004}
}

@article{Bubeck11,
  title={Pure Exploration in Finitely-Armed and Continuous-Armed Bandits},
  author={Bubeck, Sébastien and Munos, Rémi and Stoltz, Gilles},
  journal={Theoretical Computer Science},
  volume={412},
  number={19},
  pages={1832--1852},
  year={2011}
}

@inproceedings{Honda10,
  title={An Asymptotically Optimal Bandit Algorithm for Bounded Support Models},
  author={Honda, Junya and Takemura, Akimichi},
  booktitle={Conference on Learning Theory},
  year={2010}
}

@techreport{Settles:2010,
  title={Active Learning Literature Survey},
  author={Settles, Burr},
  institution={University of Wisconsin, Madison},
  year={2010}
}

@book{PowellRyzhov12,
  title={Optimal Learning},
  author={Powell, Warren and Ryzhov, Ilya},
  year={2012},
  publisher={John Wiley \& Sons}
}

@article{Frazier08,
  title={A Knowledge-Gradient Policy for Sequential Information Collection},
  author={Frazier, Peter I and Powell, Warren B and Dayanik, Savas},
  journal={SIAM Journal on Control and Optimization},
  volume={47},
  number={5},
  pages={2410--2439},
  year={2008}
}

@inproceedings{Strens00,
  title={A {B}ayesian Framework for Reinforcement Learning},
  author={Strens, Malcolm},
  booktitle={International Conference on Machine Learning},
  year={2000}
}